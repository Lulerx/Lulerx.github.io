---
title: java 线程进阶
date: 2020-11-24
categories: Java核心    #分类
tags: java线程         #标签
toc: true  #是否启用内容索引
top: false #是否置顶 true或者注释
typora-root-url: ..
---

## 概述

&nbsp;&nbsp;&nbsp;&nbsp; 计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的**高速缓存**（Cache）来作为内存与处理器之间的缓冲：**将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了**

>   在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存。
>
>   所以当多个处理器的运算任务涉及同一块主内存区域时，就有可能导致各自缓存的数据不一致。



![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxNy85LzQvMjBhOTk2ODc0NmFmYTJhZmRlNGIzNzE2YmFiZjU1Y2U_aW1hZ2VWaWV3Mi8wL3cvMTI4MC9oLzk2MC9mb3JtYXQvd2VicC9pZ25vcmUtZXJyb3IvMQ)

**Java内存模型** 

&nbsp;&nbsp;&nbsp;&nbsp; Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model,JMM）来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。

在 java 中每个线程有自己的工作内存进行数据处理，但是它们共用一个主内存。在线程处理数据的时候只是把数据从主内存中拷贝一份副数据到工作内存进行处理，然后再将处理结果同步到主内存中。但这些都是需要时间的，也就是说如果多个线程处理同一个数据，就会出现结果与我们预料不一致的情况，**也就是我们常说的线程安全问题。**

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxNy85LzQvOGY5ODMzMGRjOGFmNGNlOGNmNTM5N2EwMTMzMDhlYzI_aW1hZ2VWaWV3Mi8wL3cvMTI4MC9oLzk2MC9mb3JtYXQvd2VicC9pZ25vcmUtZXJyb3IvMQ">

>   【注意】这里所讲的主内存、工作内存与我们通常所讲的Java内存区域中的 Java 堆、栈、方法区等并不是同一个层次的内存划分，这两者基本上是没有关系的，如果两者一定要勉强对应起来，那从变量、主内存、工作内存的定义来看，主内存主要对应于 Java 堆中的对象实例数据部分，而工作内存则对应于虚拟机栈中的部分区域。

## 1. 线程安全

**什么是线程安全？**

定义：如果一个对象可以安全地被多个线程同时使用，那它就是线程安全的。

线程安全的实现方法可分为：互斥同步、非阻塞同步

### 1.1 互斥同步

同步是指在多个线程并发访问共享数据时，保证共享数据再同一个时刻只被一个线程使用。而互斥是实现同步的一种手段，临界区、互斥量、信号量都是主要的互斥的实现方式。

实现同步的方式有：synchronized 关键字、RenntrantLock 重入锁

对于 synchronized 同步块而言，同步块在已进入的线程执行完之前，会阻塞后面其他线程的进入。但 Java 线程是映射到操作系统的原生线程之上的，如果要阻塞或唤醒一个线程，都需要操作系统来帮忙完成，这些都是需要消耗处理器时间的，这其中消耗的时间可能比用户代码执行的时间还要长，**所以 synchronized 是 Java 语言中一个重量级的操作。**

RenntrantLock 增加啊了一些高级功能：

1.  **等待可中断：**当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。
2.  **可实现公平锁：**公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来一次获得锁。而非公平锁不保证这点，锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized 的锁是非公平的，RenntrantLock 默认也是非公平，但可以通过带有布尔值的构造函数要求使用公平锁。
3.  **锁可绑定多个条件：**RenntrantLock 对象可以同时绑定多个 Condition 对象，只需多次调用 newCondition() 方法即可。

>   【对比】synchronized 和 RenntrantLock 从性能上考虑，在 JDK 1.6 之后 synchronized 性能更好，所以还是提倡在 synchronized 能实现需求的情况下，优先使用 synchronized 来进行同步。

### 1.2 非阻塞同步

互斥同步做主要的问题就是进行线程阻塞和唤醒所带来的性能问题，这种同步也称之为阻塞同步。

随着硬件指令集的发展，我们又了另一种乐观的并发策略：通俗地说就是先进行操作，如果没有其他线程争用共享数据，那操作就成功了；**如果共享数据有争用，产生了冲突，那就采取补偿措施（最常见的措施就是不断尝试，直到成功为止）**，这种策略不需要把线程挂起，因此称为**非阻塞同步**。

我们需要保证操作和冲突检测这两个步骤具备原子性，就需要用到硬件指令来完成。目前最常用的指令是：**比较并交换（ Compare-and-Swap，也称为 CAS 指令）。**

CAS 指令：需要有 3 个操作数，分别是内存地址（用 V 表示），旧的预估值（用 A 表示）和新值（用 B 表示）。**CAS 执行执行时，当且仅当 V 的值与 A 一致时，处理器才用新值 B 更新 V 的值，否则就不执行更新。**这个处理过程是一个原子操作。

## 2. 锁优化

高效并发是从JDK 1.5到JDK 1.6的一个重要改进，HotSpot虚拟机开发团队在这个版本上花费了大量的精力去实现各种锁优化技术，如**适应性自旋**（Adaptive Spinning）、**锁消除**（Lock Elimination）、**锁粗化**（Lock Coarsening）、**轻量级锁**（Lightweight Locking）和**偏向锁**（Biased Locking）等，这些技术都是为了在线程之间更高效地共享数据，以及解决竞争问题，从而提高程序的执行效率。

### 2.1 适应性自旋锁

前面提到了互斥同步对性能最大的影响是阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性能带来了很大的压力。同时，虚拟机的开发团队也注意到在许多应用上，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得。如果物理机器有一个以上的处理器，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程“稍等一下”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需让线程执行一个忙循环（自旋），这项技术就是所谓的**自旋锁**。

在JDK 1.6中引入了**自适应的自旋锁**。自适应意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。另外，如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。有了自适应自旋，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测就会越来越准确，虚拟机就会变得越来越“聪明”了。

### 2.2 锁消除

锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持，如果判断在一段代码中，堆上的所有数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当做栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行。

### 2.3 锁粗化

原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小——只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待锁的线程也能尽快拿到锁。

大部分情况下，上面的原则都是正确的，但是如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。

### 2.4 偏向锁

偏向锁也是JDK 1.6中引入的一项锁优化，它的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS操作都不做了。

偏向锁的“偏”，就是偏心的“偏”、偏袒的“偏”，它的意思是这个锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。

